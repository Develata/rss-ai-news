import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from openai import OpenAI
from sqlalchemy.exc import SQLAlchemyError

from news_crawler.core.category_strategies import get_strategy
from news_crawler.core.database import NewsArticle
from news_crawler.core.settings import get_settings
from news_crawler.utils.common import truncate_text


def _get_client():
    settings = get_settings()
    if not settings.ai.api_key:
        return None
    return OpenAI(api_key=settings.ai.api_key, base_url=settings.ai.base_url)


def get_ai_summary(text: str, category: str = "é€šç”¨") -> str:
    """
    ä½¿ç”¨åˆ†ç±»ç­–ç•¥è·å–AIæ‘˜è¦ã€‚
    æ ¹æ®categoryé€‰æ‹©å¯¹åº”çš„promptæ¨¡æ¿å’Œæœ€å¤§è¾“å…¥å­—ç¬¦æ•°ã€‚
    """
    client = _get_client()
    if not client:
        return f"âš ï¸ API Key missing: {text[:200]}..."

    settings = get_settings()
    model_name = settings.ai.model
    base_delay = settings.ai.base_delay
    max_retries = settings.ai.max_retries

    # è·å–åˆ†ç±»ç­–ç•¥
    strategy = get_strategy(category)
    system_prompt = strategy.prompt
    max_input_chars = strategy.max_input_chars

    # æ™ºèƒ½æˆªæ–­è¾“å…¥æ–‡æœ¬
    truncated_text = truncate_text(text, max_input_chars)

    last_err = None

    for attempt in range(1, max_retries + 1):
        try:
            start_ts = time.time()
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": truncated_text},
                ],
                temperature=0.3,
            )
            elapsed = time.time() - start_ts
            if base_delay > 0 and elapsed < base_delay:
                time.sleep(base_delay - elapsed)

            return response.choices[0].message.content.strip()

        except Exception as e:
            err_msg = str(e)
            last_err = e

            if (
                "rate limit" in err_msg.lower()
                or "429" in err_msg
                or "quota" in err_msg.lower()
            ):
                backoff = base_delay * attempt
                time.sleep(backoff)
                continue
            else:
                return f"âŒ AI Error: {e.__class__.__name__}: {err_msg}"

    return f"âŒ AI Error: {last_err.__class__.__name__}: {last_err}"


def get_custom_ai_response(user_text: str, system_prompt: str) -> str:
    client = _get_client()
    if not client:
        return "AIé…ç½®ç¼ºå¤±ã€‚"
    try:
        settings = get_settings()
        response = client.chat.completions.create(
            model=settings.ai.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text[:4000]},
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"AI ç”Ÿæˆå¤±è´¥: {e}"


def _process_single_article_logic(art_id, content_text, category, title):
    """å¤„ç†å•ç¯‡æ–‡ç« çš„AIæ‘˜è¦é€»è¾‘ï¼Œä½¿ç”¨åˆ†ç±»ç­–ç•¥è¿›è¡Œè¯„åˆ†ã€‚"""
    strategy = get_strategy(category)
    try:
        raw_output = get_ai_summary(content_text, category)

        if "PASS" in raw_output and len(raw_output) < 20:
            return {
                "id": art_id,
                "status": "filtered",
                "summary": "AIè¿‡æ»¤ï¼šä½ä»·å€¼",
                "tags": "",
                "score": 0,
                "raw": raw_output,
            }

        tags = ""
        score = 50

        score_match = re.search(r"(?:SCORE|åˆ†æ•°)[^\d]*(\d+)", raw_output, re.IGNORECASE)
        if score_match:
            raw_score = int(score_match.group(1))
            # åº”ç”¨åˆ†ç±»æƒé‡è¿›è¡ŒåŠ æƒè®¡ç®—ï¼ˆå¦‚æœ‰å¤šç»´åº¦è¯„åˆ†ï¼‰
            score = min(100, max(0, raw_score))

        tags_match = re.search(
            r"(?:TAGS|æ ‡ç­¾)[\|\s:ï¼š]*([^\n\|]+)", raw_output, re.IGNORECASE
        )
        if tags_match:
            tags = tags_match.group(1).strip()

        clean_summary = re.split(r"\|TAGS\||\|SCORE\|", raw_output)[0].strip()
        clean_summary = clean_summary.strip('"').strip("'")

        return {
            "id": art_id,
            "status": "success",
            "summary": clean_summary,
            "tags": tags,
            "score": score,
            "title_preview": title[:15],
            "category": category,
        }

    except Exception as e:
        return {"id": art_id, "status": "error", "error_msg": str(e)}


def process_new_summaries(session, batch_size: int = 50, commit_every: int = 10) -> int:
    """
    å¤„ç†æœªAIå¤„ç†çš„æ–‡ç« ï¼Œä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼å‡å°‘å†…å­˜å ç”¨ã€‚
    æŒ‰åˆ†ç±»åˆ†æ‰¹å¤„ç†ï¼Œæ¯ä¸ªåˆ†ç±»ä½¿ç”¨å¯¹åº”çš„ç­–ç•¥ã€‚
    """
    total_success = 0

    while True:
        # ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼ï¼šåªæŸ¥è¯¢IDï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡ç« åˆ°å†…å­˜
        article_ids = (
            session.query(NewsArticle.id)
            .filter(NewsArticle.is_ai_processed == False)
            .limit(batch_size)
            .all()
        )

        if not article_ids:
            if total_success == 0:
                print(" ğŸ’¤ No new articles to process.")
            break

        # åˆ†æ‰¹åŠ è½½æ–‡ç« è¯¦æƒ…
        ids = [aid[0] for aid in article_ids]
        articles = session.query(NewsArticle).filter(NewsArticle.id.in_(ids)).all()

        art_map = {art.id: art for art in articles}
        settings = get_settings()
        print(
            f" ğŸš€ Processing {len(articles)} articles with AI (Concurrency: {settings.ai.max_workers})..."
        )

        success_count_this_round = 0
        with ThreadPoolExecutor(max_workers=settings.ai.max_workers) as executor:
            futures = []
            for art in articles:
                cat_name = art.category if art.category else "NetTech_Hardcore"
                strategy = get_strategy(cat_name)
                # ä½¿ç”¨ç­–ç•¥çš„max_input_charsè¿›è¡Œé¢„æˆªæ–­
                truncated_content = truncate_text(art.content_text, strategy.max_input_chars)
                futures.append(
                    executor.submit(
                        _process_single_article_logic,
                        art.id,
                        truncated_content,
                        cat_name,
                        art.title,
                    )
                )

            for future in as_completed(futures):
                res = future.result()
                art = art_map[res["id"]]

                if res["status"] == "success":
                    art.summary = res["summary"]
                    art.ai_tags = res["tags"]
                    art.importance_score = res["score"]
                    art.is_ai_processed = True
                    category_hint = res.get("category", "")[:8]
                    print(f" âœ… [{category_hint}] Score: {res['score']} | {res['title_preview']}...")
                    total_success += 1
                    success_count_this_round += 1

                elif res["status"] == "filtered":
                    art.summary = res["summary"]
                    art.ai_tags = ""
                    art.importance_score = 0
                    art.is_ai_processed = True
                    print(f" ğŸ—‘ï¸ [Filtered] {art.title[:15]}...")
                    total_success += 1
                    success_count_this_round += 1

                elif res["status"] == "error":
                    print(
                        f" âŒ Error processing ID {res['id']}: {res.get('error_msg')}"
                    )

                if success_count_this_round >= commit_every:
                    try:
                        session.commit()
                    except SQLAlchemyError as e:
                        print(f" âŒ Commit failed during AI processing: {e}")
                        session.rollback()
                    success_count_this_round = 0

        try:
            session.commit()
        except SQLAlchemyError as e:
            print(f" âŒ Commit failed at end of batch: {e}")
            session.rollback()

    return total_success
