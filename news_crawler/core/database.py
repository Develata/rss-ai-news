from __future__ import annotations

import sys
from datetime import datetime, timezone
from functools import lru_cache

from sqlalchemy import Boolean, Column, DateTime, Index, Integer, String, Text, create_engine
from sqlalchemy.orm import declarative_base, sessionmaker

from news_crawler.core.settings import get_settings

Base = declarative_base()


class NewsArticle(Base):
    __tablename__ = "raw_news"

    id = Column(Integer, primary_key=True)
    title = Column(String(512), nullable=False)
    link = Column(String(1024), unique=True, nullable=False)
    content_hash = Column(String(64), index=True)
    content_text = Column(Text)
    source = Column(String(50))
    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc), index=True)

    summary = Column(Text, nullable=True)
    ai_tags = Column(String(255), nullable=True)
    is_ai_processed = Column(Boolean, default=False, index=True)
    category = Column(String(50), index=True, nullable=True)
    importance_score = Column(Integer, default=0, index=True)

    # å¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
    __table_args__ = (
        # AIå¤„ç†æŸ¥è¯¢ï¼šæŸ¥æ‰¾æœªå¤„ç†çš„æ–‡ç« 
        Index('ix_raw_news_ai_pending', 'is_ai_processed', postgresql_where=is_ai_processed == False),
        # æŠ¥è¡¨æŸ¥è¯¢ï¼šæŒ‰åˆ†ç±»+æ—¶é—´+åˆ†æ•°æŸ¥è¯¢
        Index('ix_raw_news_report', 'category', 'created_at', 'importance_score'),
    )


@lru_cache(maxsize=1)
def get_engine():
    settings = get_settings()
    db_uri = settings.db.build_uri()
    if not db_uri:
        raise RuntimeError(
            "Database is not configured. Please set DB_URI or (DB_HOST/DB_USER/DB_PASS/DB_PORT)."
        )

    return create_engine(
        db_uri,
        pool_size=5,
        pool_recycle=1800,
        pool_pre_ping=True,
        connect_args={"connect_timeout": 10},
    )


def _try_create_sessionmaker():
    try:
        engine = get_engine()
    except Exception:
        return None
    return sessionmaker(bind=engine, autoflush=False, expire_on_commit=False)


SessionLocal = _try_create_sessionmaker()

try:
    engine = get_engine()
except Exception:
    engine = None


if __name__ == "__main__":
    from news_crawler.core.bootstrap import bootstrap

    bootstrap()
    print("ğŸ”Œ æ­£åœ¨è¿æ¥ Azure æ•°æ®åº“...")
    try:
        Base.metadata.create_all(get_engine())
        print("\nâœ…âœ…âœ… æˆåŠŸï¼æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œè¡¨ç»“æ„å·²åŒæ­¥ï¼")
    except Exception as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
