import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from zoneinfo import ZoneInfo

from news_crawler.core.config import REPORT_CONFIGS
from news_crawler.core.database import NewsArticle
from news_crawler.services.ai_service import get_custom_ai_response
from news_crawler.services.publisher_service import GitHubPublisher

try:
    from news_crawler.utils.logger import logger
except ImportError:
    import logging

    logger = logging.getLogger(__name__)


def generate_excerpt(articles, config):
    if not articles:
        return "æœ¬æœŸæ— å†…å®¹ã€‚"

    max_titles = int(config.get("excerpt_max_titles") or 15)
    titles_list = "\n".join([f"- {art.title}" for art in articles[:max_titles]])

    system_prompt = (config.get("excerpt_prompt") or "").strip()
    if not system_prompt:
        system_prompt = (
            f"ä½ æ˜¯ä¸€ä¸ªç§‘æŠ€æ–°é—»ä¸»ç¼–ã€‚è¯·æ ¹æ®ä»¥ä¸‹ã€{config['title_prefix']}ã€‘æ¿å—çš„æ–°é—»æ ‡é¢˜åˆ—è¡¨ï¼Œ"
            "å†™ä¸€æ®µç®€çŸ­çš„æ—¥æŠ¥å¯¼è¯»ï¼ˆExcerptï¼‰ã€‚è¦æ±‚è¯­æ°”ä¸“ä¸šå®¢è§‚ï¼Œ80å­—ä»¥å†…ã€‚"
        )

    try:
        excerpt = get_custom_ai_response(titles_list, system_prompt)
        if not excerpt:
            return "ä»Šæ—¥ç§‘æŠ€çƒ­ç‚¹é€Ÿè§ˆã€‚"
        return excerpt.replace('"', "").replace("'", "")
    except Exception as e:
        logger.warning(f"âš ï¸ ç”Ÿæˆå¯¼è¯»å¤±è´¥: {e}")
        return "ä»Šæ—¥ç§‘æŠ€çƒ­ç‚¹é€Ÿè§ˆã€‚"


def generate_md_content(articles, config):
    if not articles:
        return None

    tz = ZoneInfo("Asia/Shanghai")
    now = datetime.now(tz)
    date_str = f"{now.year}-{now.month}-{now.day}"

    excerpt_text = generate_excerpt(articles, config)
    if not excerpt_text:
        excerpt_text = "æš‚æ— æ‘˜è¦"

    raw_title = f"{config['title_prefix']} {date_str}"

    safe_title = raw_title.replace('"', '\\"').strip()
    safe_excerpt = excerpt_text.replace('"', '\\"').replace("\n", " ").strip()

    md = [
        "---",
        f'title: "{safe_title}"',
        f"date: {date_str}",
        f'excerpt: "{safe_excerpt}"',
        "---",
        "",
        f"# {safe_title}\n",
        f"> {excerpt_text}\n",
    ]

    badge_enabled = bool(config.get("badge_enabled", True))

    for art in articles:
        title = art.title.replace("|", "-").replace("[", "(").replace("]", ")").strip()

        tags = "".join([f"`{t.strip()}` " for t in (art.ai_tags or "").split(",") if t.strip()])

        if badge_enabled:
            md.append(f'## {title} <Badge type="tip" text="{art.importance_score}" />\n')
        else:
            md.append(f"## {title}\n")
        if tags:
            md.append(f"- **Tags:** {tags}\n")

        md.append(f"- **Source:** `{art.source}` | [é˜…è¯»åŸæ–‡]({art.link})\n")

        summary_text = art.summary if art.summary else "æš‚æ— æ‘˜è¦"
        md.append(f"> {summary_text}\n\n")
        md.append("---\n")

    return "\n".join(md)


def run_publishing_job(session):
    publisher = GitHubPublisher()
    local_root = (os.getenv("REPORT_LOCAL_DIR") or "./data/news").strip() or "./data/news"
    local_root_path = Path(local_root)

    # 1. å‡†å¤‡ç¯å¢ƒ
    tz = ZoneInfo("Asia/Shanghai")
    now = datetime.now(tz)
    current_year = str(now.year)
    current_date_file = now.strftime("%Y%m%d")
    time_window = datetime.now(timezone.utc) - timedelta(hours=25)

    # 2. æŸ¥è¯¢æ•°æ®
    all_articles = (
        session.query(NewsArticle)
        .filter(
            NewsArticle.created_at >= time_window,
            NewsArticle.is_ai_processed.is_(True),
            NewsArticle.category.in_(list(REPORT_CONFIGS.keys())),
        )
        .order_by(
            NewsArticle.category,
            NewsArticle.importance_score.desc(),
            NewsArticle.created_at.desc(),
        )
        .all()
    )

    # 3. æ•°æ®åˆ†ç»„
    articles_by_category = {}
    for art in all_articles:
        if art.category not in articles_by_category:
            articles_by_category[art.category] = []
        articles_by_category[art.category].append(art)

    # 4. ç”Ÿæˆå†…å®¹å¹¶æš‚å­˜
    pending_updates = []  # [{"path": "...", "content": "..."}]
    generated_titles = []

    for category_key, cfg in REPORT_CONFIGS.items():
        try:
            max_items = int(cfg.get("max_items") or 10)
            articles = articles_by_category.get(category_key, [])[:max_items]
            if articles:
                logger.info(
                    f"    ğŸ› ï¸ Generating MD for {cfg['title_prefix']} ({len(articles)} items)..."
                )

                content = generate_md_content(articles, cfg)
                folder_name = cfg.get("folder", "Other")
                file_path = f"{folder_name}/{current_year}/{current_date_file}.md"

                pending_updates.append({"path": file_path, "content": content})
                generated_titles.append(cfg["title_prefix"])
            else:
                logger.info(f"    ğŸ˜´ Skipped {cfg['title_prefix']}")

        except Exception as e:
            logger.error(f"    âŒ ç”Ÿæˆæ—¥æŠ¥å¤±è´¥ [{category_key}]")
            logger.error(f"       é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"       é”™è¯¯ä¿¡æ¯: {e}")
            logger.error("       ğŸ’¡ è¯¥åˆ†ç±»å°†è¢«è·³è¿‡ï¼Œä¸å½±å“å…¶ä»–åˆ†ç±»")
            continue

    # 5. æœ¬åœ°è½ç›˜ï¼ˆä¸ä¸Šä¼ åçš„ç›¸åŒç›¸å¯¹è·¯å¾„ç»“æ„ï¼‰ï¼Œä¸å½±å“åç»­æ¨é€
    if pending_updates:
        try:
            for item in pending_updates:
                rel_path = (item.get("path") or "").lstrip("/\\")
                out_path = (local_root_path / rel_path).resolve()
                out_path.parent.mkdir(parents=True, exist_ok=True)
                out_path.write_text(item.get("content") or "", encoding="utf-8")
            logger.info(f"ğŸ’¾ æœ¬åœ°å·²ä¿å­˜ {len(pending_updates)} ä¸ª Markdown åˆ° {local_root_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ æœ¬åœ°ä¿å­˜ Markdown å¤±è´¥ï¼ˆä¸å½±å“æ¨é€ï¼‰ï¼š{e}")

    # 6. ä¸€æ¬¡æ€§æ¨é€ (One Commit)
    published_count = len(pending_updates)
    if published_count > 0:
        try:
            # æ„é€  Commit Message
            commit_msg = (
                f"ğŸ¤– Bot Update: {current_date_file} Report ({', '.join(generated_titles)})"
            )

            # è°ƒç”¨æ‰¹é‡æ¨é€
            publisher.publish_changes(pending_updates, commit_msg)

        except ValueError as e:
            # GitHub é…ç½®æˆ–è®¤è¯é”™è¯¯
            logger.error("âŒ GitHub é…ç½®é”™è¯¯")
            logger.error(f"   {e}")
            return 0
        except RuntimeError as e:
            # GitHub API æ“ä½œé”™è¯¯
            logger.error("âŒ GitHub æ¨é€å¤±è´¥")
            logger.error(f"   {e}")
            return 0
        except Exception as e:
            # å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
            logger.error(f"âŒ å‘å¸ƒå¤±è´¥: {type(e).__name__}")
            logger.error(f"   é”™è¯¯è¯¦æƒ…: {e}")
            logger.error("   ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ GitHub é…ç½®")
            return 0

    return published_count
